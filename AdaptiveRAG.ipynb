{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wf-eMaWvcFEt"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "! pip install -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub pinecone-client langchain langgraph  tavily-python \"unstructured[pdf]\"\n",
        "! pip install langchain_pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
        "### Tracing (optional)\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "777b2HjIcQ-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9GU3kpCbfd3E",
        "outputId": "807d9e74-d58d-4625-fa17-1e7d209b2a04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.1.2-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.2.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.25.2)\n",
            "Collecting pinecone-client<5,>=3.2.2 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-4.1.2-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.4/216.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.1.93)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (8.5.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<5,>=3.2.2->langchain_pinecone) (2024.7.4)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<5,>=3.2.2->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<5,>=3.2.2->langchain_pinecone) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<5,>=3.2.2->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<5,>=3.2.2->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.7)\n",
            "Installing collected packages: pinecone-client, langchain_pinecone\n",
            "  Attempting uninstall: pinecone-client\n",
            "    Found existing installation: pinecone-client 5.0.0\n",
            "    Uninstalling pinecone-client-5.0.0:\n",
            "      Successfully uninstalled pinecone-client-5.0.0\n",
            "Successfully installed langchain_pinecone-0.1.2 pinecone-client-4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Build Index\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "### from langchain_cohere import CohereEmbeddings\n",
        "\n",
        "# Set embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Docs to index\n",
        "\n",
        "doc_path = \"/content/anjuai.pdf\"\n",
        "# Load\n",
        "loader =PyPDFLoader(doc_path)\n",
        "documents = loader.load()\n",
        "# docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500, chunk_overlap=200\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"f2ee2cda-ce72-4788-8254-8d33f6a32558\"\n",
        "# Add to vectorstore\n",
        "Pinecone(environment='us-east-1-aws')\n",
        "vectorstore = PineconeVectorStore.from_documents(\n",
        "        documents, embeddings, index_name= \"indya-cleo\")\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "hDRG1iAzdQAp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Router\n",
        "\n",
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Data model\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "\n",
        "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
        "        ...,\n",
        "        description=\"Given a user question choose to route it to vectorstore, web search or use Your Knowledge if you know.\",\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
        "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
        "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_router = route_prompt | structured_llm_router\n",
        "# print(\n",
        "#     question_router.invoke(\n",
        "#         {\"question\": \"what is ai\"}\n",
        "#     )\n",
        "# )\n",
        "# print(question_router.invoke({\"question\": \"Who  is the ceo of Bluescarf.ai\"}))"
      ],
      "metadata": {
        "id": "D9HEMmC-GfrF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"who is the ceo of bluescarf.ai?\"\n",
        "# docs = retriever.get_relevant_documents(question)\n",
        "# doc_txt = docs[1].page_content\n",
        "# print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
      ],
      "metadata": {
        "id": "Yd1a0vN2GjJq"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "# print(generation)"
      ],
      "metadata": {
        "id": "uECyQOG2Glks"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hallucination Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
        "# hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
      ],
      "metadata": {
        "id": "vSETJceWHGtH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Answer Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "answer_grader = answer_prompt | structured_llm_grader\n",
        "# answer_grader.invoke({\"question\": question, \"generation\": generation})"
      ],
      "metadata": {
        "id": "2FIe28uIHKwj"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Question Re-writer\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "# question_rewriter.invoke({\"question\": question})"
      ],
      "metadata": {
        "id": "qz685IMJHNxF"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web Search Tool"
      ],
      "metadata": {
        "id": "no2lm-JdHwBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Search\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ],
      "metadata": {
        "id": "7f5DT46C1Ak8"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph state"
      ],
      "metadata": {
        "id": "EakGx_jpHmPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]"
      ],
      "metadata": {
        "id": "8CwUX7881sQv"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Flow"
      ],
      "metadata": {
        "id": "1NAhJZTfHoNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question}\n",
        "\n",
        "\n",
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    return {\"documents\": web_results, \"question\": question}\n",
        "\n",
        "\n",
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to web search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\"\n",
        "    elif source.datasource == \"web_search\":\n",
        "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
        "        return \"web_search\"\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    filtered_documents = state[\"documents\"]\n",
        "\n",
        "    if not filtered_documents:\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"\n",
        "    Determines whether the generation is grounded in the document and answers question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score = hallucination_grader.invoke(\n",
        "        {\"documents\": documents, \"generation\": generation}\n",
        "    )\n",
        "    grade = score.binary_score\n",
        "\n",
        "    # Check hallucination\n",
        "    if grade == \"yes\":\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "        # Check question-answering\n",
        "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
        "        return \"not supported\""
      ],
      "metadata": {
        "id": "udpU4_m52FTf"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Build Graph"
      ],
      "metadata": {
        "id": "MwwZYzauH4mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"web_search\", web_search)  # web search\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generatae\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "\n",
        "# Build graph\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"not supported\": \"generate\",\n",
        "        \"useful\": END,\n",
        "        \"not useful\": \"transform_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "oi-qNiF82J2I"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"Tell me about ai and its branches in detail upto 1000 words\"\n",
        "}\n",
        "iteration_count = 0\n",
        "for output in app.stream(inputs):\n",
        "    iteration_count += 1\n",
        "    print(f\"Iteration: {iteration_count}\")  # Track iterations\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        pprint(value) # Print the full state at each node\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation (if reached)\n",
        "if 'generation' in value:\n",
        "    pprint(value[\"generation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tK9W_dZiIGwK",
        "outputId": "7b51c8a6-fbe7-4f0a-af82-c15685d8f620"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO WEB SEARCH---\n",
            "---WEB SEARCH---\n",
            "Iteration: 1\n",
            "\"Node 'web_search':\"\n",
            "{'documents': Document(page_content='Branches of AI: A Simple Guide to 28 Fields of Artificial Intelligence\\nAndrew Wilson\\nWith all the buzz around generative AI, it’s easy to forget that Artificial Intelligence is actually a massive field with many individual branches within computer science.\\n Text Formatting: How to Improve Convos\\nJuly 13, 2023\\nCharacter AI API: Best Options & Alternatives\\nJuly 9, 2023\\nBest Midjourney Settings: Getting Started\\nJune 27, 2023\\n The 11 Best Character AI Bots (According to Reddit)\\nJune 26, 2023\\nOriginality Checker: Complete Guide & Best Tools [Aug 2023]\\nJune 23, 2023\\nFuture Proof Yourself for $0.\\n About the Author\\nAndrew Wilson\\nRelated Posts\\n13 Character AI Ideas for Roleplay, Scenarios, and Settings\\nJuly 14, 2023\\nCharacter AI Table of Contents\\nBranches of AI Infographic\\nMachine Learning\\nThe first type of AI we will cover is machine learning.\\n6. Fuzzy Logic. AI is essentially a computer system that works with yes/no, black/white values known as boolean. Fuzzy logic gives AI the freedom to explore beyond this point and opens the door to human reasoning, such as maybe, definitely, and don\\'t know.\\nLearners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.\\n$1 unlocks unlimited opportunities\\nCoursera Footer\\nPopular AI Content\\nPopular Programs\\nPopular Skills\\nPopular Career Resources\\nCoursera\\nCommunity\\nMore Yet, despite the many philosophical disagreements over whether “true” intelligent machines actually exist, when most people use the term AI today, they’re referring to a suite of machine learning-powered technologies, such as Chat GPT or computer vision, that enable machines to perform tasks that previously only humans can do like generating written content, steering a car, or analyzing data.\\n For Everyone course, you’ll learn what AI can realistically do and not do, how to spot opportunities to apply AI to problems in your own organization, and what it feels like to build machine learning and data science projects.\\n Regardless of how far we are from achieving AGI, you can assume that when someone uses the term artificial general intelligence, they’re referring to the kind of sentient computer programs and machines that are commonly found in popular science fiction.\\n Some of the most common examples of AI in use today include:\\nChatGPT: Uses large language models (LLMs) to generate text in response to questions or comments posed to it.\\n\\nThe current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010\\'s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\n AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. \"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California\\'s Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\n\\nAccording to IDC, worldwide AI spending will climb from $85.3 billion in 2022 to over $204 billion by 2027. With promising growth prospects ahead, let\\'s examine the top branches powering AI\\'s expanding capabilities. Machine Learning: Teaching Machines to Learn Independently. Machine learning is one of the most prominent domains of AI today.'),\n",
            " 'question': 'Tell me about ai and its branches in detail upto 1000 words'}\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
            "Iteration: 2\n",
            "\"Node 'generate':\"\n",
            "{'documents': Document(page_content='Branches of AI: A Simple Guide to 28 Fields of Artificial Intelligence\\nAndrew Wilson\\nWith all the buzz around generative AI, it’s easy to forget that Artificial Intelligence is actually a massive field with many individual branches within computer science.\\n Text Formatting: How to Improve Convos\\nJuly 13, 2023\\nCharacter AI API: Best Options & Alternatives\\nJuly 9, 2023\\nBest Midjourney Settings: Getting Started\\nJune 27, 2023\\n The 11 Best Character AI Bots (According to Reddit)\\nJune 26, 2023\\nOriginality Checker: Complete Guide & Best Tools [Aug 2023]\\nJune 23, 2023\\nFuture Proof Yourself for $0.\\n About the Author\\nAndrew Wilson\\nRelated Posts\\n13 Character AI Ideas for Roleplay, Scenarios, and Settings\\nJuly 14, 2023\\nCharacter AI Table of Contents\\nBranches of AI Infographic\\nMachine Learning\\nThe first type of AI we will cover is machine learning.\\n6. Fuzzy Logic. AI is essentially a computer system that works with yes/no, black/white values known as boolean. Fuzzy logic gives AI the freedom to explore beyond this point and opens the door to human reasoning, such as maybe, definitely, and don\\'t know.\\nLearners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.\\n$1 unlocks unlimited opportunities\\nCoursera Footer\\nPopular AI Content\\nPopular Programs\\nPopular Skills\\nPopular Career Resources\\nCoursera\\nCommunity\\nMore Yet, despite the many philosophical disagreements over whether “true” intelligent machines actually exist, when most people use the term AI today, they’re referring to a suite of machine learning-powered technologies, such as Chat GPT or computer vision, that enable machines to perform tasks that previously only humans can do like generating written content, steering a car, or analyzing data.\\n For Everyone course, you’ll learn what AI can realistically do and not do, how to spot opportunities to apply AI to problems in your own organization, and what it feels like to build machine learning and data science projects.\\n Regardless of how far we are from achieving AGI, you can assume that when someone uses the term artificial general intelligence, they’re referring to the kind of sentient computer programs and machines that are commonly found in popular science fiction.\\n Some of the most common examples of AI in use today include:\\nChatGPT: Uses large language models (LLMs) to generate text in response to questions or comments posed to it.\\n\\nThe current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010\\'s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\n AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. \"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California\\'s Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\n\\nAccording to IDC, worldwide AI spending will climb from $85.3 billion in 2022 to over $204 billion by 2027. With promising growth prospects ahead, let\\'s examine the top branches powering AI\\'s expanding capabilities. Machine Learning: Teaching Machines to Learn Independently. Machine learning is one of the most prominent domains of AI today.'),\n",
            " 'generation': 'Artificial Intelligence (AI) is a broad field within computer '\n",
            "               'science that encompasses various branches aimed at enabling '\n",
            "               'machines to perform tasks that typically require human '\n",
            "               'intelligence. Some of the key branches include Machine '\n",
            "               'Learning, which focuses on teaching machines to learn from '\n",
            "               'data independently, and Fuzzy Logic, which allows AI to handle '\n",
            "               'reasoning that is not strictly binary. Other notable areas '\n",
            "               'include computer vision, natural language processing, and '\n",
            "               'probabilistic algorithms, each contributing to the diverse '\n",
            "               'applications and capabilities of AI.',\n",
            " 'question': 'Tell me about ai and its branches in detail upto 1000 words'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 3\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': Document(page_content='Branches of AI: A Simple Guide to 28 Fields of Artificial Intelligence\\nAndrew Wilson\\nWith all the buzz around generative AI, it’s easy to forget that Artificial Intelligence is actually a massive field with many individual branches within computer science.\\n Text Formatting: How to Improve Convos\\nJuly 13, 2023\\nCharacter AI API: Best Options & Alternatives\\nJuly 9, 2023\\nBest Midjourney Settings: Getting Started\\nJune 27, 2023\\n The 11 Best Character AI Bots (According to Reddit)\\nJune 26, 2023\\nOriginality Checker: Complete Guide & Best Tools [Aug 2023]\\nJune 23, 2023\\nFuture Proof Yourself for $0.\\n About the Author\\nAndrew Wilson\\nRelated Posts\\n13 Character AI Ideas for Roleplay, Scenarios, and Settings\\nJuly 14, 2023\\nCharacter AI Table of Contents\\nBranches of AI Infographic\\nMachine Learning\\nThe first type of AI we will cover is machine learning.\\n6. Fuzzy Logic. AI is essentially a computer system that works with yes/no, black/white values known as boolean. Fuzzy logic gives AI the freedom to explore beyond this point and opens the door to human reasoning, such as maybe, definitely, and don\\'t know.\\nLearners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.\\n$1 unlocks unlimited opportunities\\nCoursera Footer\\nPopular AI Content\\nPopular Programs\\nPopular Skills\\nPopular Career Resources\\nCoursera\\nCommunity\\nMore Yet, despite the many philosophical disagreements over whether “true” intelligent machines actually exist, when most people use the term AI today, they’re referring to a suite of machine learning-powered technologies, such as Chat GPT or computer vision, that enable machines to perform tasks that previously only humans can do like generating written content, steering a car, or analyzing data.\\n For Everyone course, you’ll learn what AI can realistically do and not do, how to spot opportunities to apply AI to problems in your own organization, and what it feels like to build machine learning and data science projects.\\n Regardless of how far we are from achieving AGI, you can assume that when someone uses the term artificial general intelligence, they’re referring to the kind of sentient computer programs and machines that are commonly found in popular science fiction.\\n Some of the most common examples of AI in use today include:\\nChatGPT: Uses large language models (LLMs) to generate text in response to questions or comments posed to it.\\n\\nThe current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[210]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[211] Personalities such as Stephen Hawking, Bill Gates, Elon Musk have expressed concern about existential risk from AI.[212]\\nIn the early 2010\\'s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[213]\\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.[214]\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI and in 2023 many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[215]\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[198] Risk estimates vary; for example, in the 2010s Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[q][200] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology (rather than social policy) creates unemployment (as opposed to redundancies).[196]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[201] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[202]\\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.[203][204]\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. The reason that deep learning performs so well in so many applications is not known as of 2023.[112]\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[j]\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[k]\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training.[121]\\nHistorically, specialized languages, such as Lisp, Prolog, and others, had been used.\\n AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[83]\\nBayesian networks[84]\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm),[g][86]\\nlearning (using the expectation-maximization algorithm),[h][88]\\nplanning (using decision networks)[89]\\nand perception (using dynamic Bayesian networks).[90]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[91]\\nand information value theory.[92]\\nThese tools include models such as Markov decision processes,\\n[93]\\ndynamic decision networks,[90]\\ngame theory and mechanism design.[94]\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. \"[ae]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[292]\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights.[293]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[294]\\nThis issue has been considered in fiction for centuries,[295]\\nand is now being considered by, for example, California\\'s Institute for the Future; however, critics argue that the discussion is premature.[296]\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[284]\\n\\nAccording to IDC, worldwide AI spending will climb from $85.3 billion in 2022 to over $204 billion by 2027. With promising growth prospects ahead, let\\'s examine the top branches powering AI\\'s expanding capabilities. Machine Learning: Teaching Machines to Learn Independently. Machine learning is one of the most prominent domains of AI today.'),\n",
            " 'question': 'Can you provide a detailed overview of artificial intelligence '\n",
            "             'and its various branches, with a word limit of 1000 words?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 4\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/anjuai.pdf'}, page_content='The\\nceo\\nof\\nanju.ai\\nis\\nknooz\\nfatima.\\nArtificial\\nIntelligence\\nServices\\nanju.ai\\nbuilds\\nsolutions\\nonly\\nrelated\\nto\\ncomputer\\nvision.'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi')],\n",
            " 'question': 'Can you provide a detailed overview of artificial intelligence '\n",
            "             'and its various branches, with a word limit of 1000 words?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 5\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed overview of artificial intelligence '\n",
            "             'and its various branches, with a word limit of 1000 words?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 6\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 7\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/anjuai.pdf'}, page_content='The\\nceo\\nof\\nanju.ai\\nis\\nknooz\\nfatima.\\nArtificial\\nIntelligence\\nServices\\nanju.ai\\nbuilds\\nsolutions\\nonly\\nrelated\\nto\\ncomputer\\nvision.'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi')],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 8\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 9\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 10\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.')],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 11\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 12\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 13\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/anjuai.pdf'}, page_content='The\\nceo\\nof\\nanju.ai\\nis\\nknooz\\nfatima.\\nArtificial\\nIntelligence\\nServices\\nanju.ai\\nbuilds\\nsolutions\\nonly\\nrelated\\nto\\ncomputer\\nvision.'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi')],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 14\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 15\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 16\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.')],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 17\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 18\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 19\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/anjuai.pdf'}, page_content='The\\nceo\\nof\\nanju.ai\\nis\\nknooz\\nfatima.\\nArtificial\\nIntelligence\\nServices\\nanju.ai\\nbuilds\\nsolutions\\nonly\\nrelated\\nto\\ncomputer\\nvision.'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi'),\n",
            "               Document(metadata={'source': '..\\\\RAG-based-Personal-AI-Assistant\\\\app\\\\data\\\\dummy.txt'}, page_content='hi')],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 20\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you give a comprehensive 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 21\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 22\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.')],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "Iteration: 23\n",
            "\"Node 'grade_documents':\"\n",
            "{'documents': [],\n",
            " 'question': 'Can you provide a detailed 1000-word overview of artificial '\n",
            "             'intelligence, covering its primary branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "Iteration: 24\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [],\n",
            " 'question': 'Could you provide an in-depth 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n",
            "---RETRIEVE---\n",
            "Iteration: 25\n",
            "\"Node 'retrieve':\"\n",
            "{'documents': [Document(metadata={'source': 'app/temp\\\\Dr Noman javed.docx'}, page_content='Interactive Session with Dr. Noman Javed - The Science of Human Learning - LSE UK\\n\\nDate 18 july 2024\\n\\nWorking on AI,CS,Human.\\n\\nDevelop models , theories from the human data psychology science. \\n\\nPsychology and human have more interactive\\n\\n3 big questions\\n\\nLife intelligent\\n\\nUniverse start\\n\\nEvolution \\n\\nPhycology and computer science become system intelligence \\n\\nHuman are intelligence features\\n\\nPsychology and ai interaction\\n\\nContinues senses the information from the environment \\n\\n5 main senses \\n\\nWe have the ability to change in the environment \\n\\nGive examples of environment and describes the diagram \\n\\nRational agent?\\n\\nOne which can think decide based on that we can act \\n\\nExample = human , Robert making human \\n\\n2 main things whats happing inside the brain ?\\n\\nHardware = brain ,software =mind \\n\\nTalk about the neuro science and psychology \\n\\nPresentation about psychology \\n\\nInformation project model our brain is just like a computer and have to process the information that means that we have algorithms and will come up with some outcomes \\n\\nWe divide into 3 parts \\n\\nSensory memory = collect environment information\\n\\nShort term memory \\n\\nLong term memory \\n\\nLearning = the change in long term memory long term change \\n\\nGiven example of book \\n\\nTurn into a good learner.\\n\\nBetter learners is not for student only \\n\\nSensory – short term- long term \\n\\nGave example of car driving \\n\\nAttention is blessing flood of information and u attending the tiny part.\\n\\nGetting important features \\n\\nInteractive sessions\\n\\nAttention mechanism work.\\n\\nShort term memory hold 5 to 6 items\\n\\nQ/A sessions \\n\\nWithout stm(short term memory) we are not able to work.                 Chunking + attention\\n\\nChunking mechanism \\n\\n12 items brain have 9\\n\\nLtm (long term memory) \\n\\nWe can make semantic chunk as well\\n\\nAll did is unconsciously \\n\\nLtm is not like computer its potentially infinite \\n\\nDiscrimination network \\n\\nWe semantically making chunking context is important \\n\\nAssociation is made \\n\\nRelevant information is there\\n\\nPart 2 \\n\\nPoverty of attention\\n\\nHerbart siamon scientist\\n\\nsaying\\n\\nA wealth of information creates a poverty of attention\\n\\nWhat social media is doing? \\n\\nI am flooding my mind with lot of information \\n\\nRed some post it will take some time for ltm\\n\\n14 – 25 mints overload no digestion \\n\\nLook at the states of mental issues \\n\\nOne of the main reason \\n\\nPast human biological same now human are different not biologically but health wise \\n\\nWe are biological tuned \\n\\nGradual change now a day’s changes occurs in seconds\\n\\nOur machine is not made for this \\n\\nHave different phases \\n\\nSame with the information process \\n\\nI am not spending the time that’s why we don’t have wisdom \\n\\nAttention is now new gold \\n\\nAs a creator of any app:\\n\\nI want to grab your  attention \\n\\nI am trying to control your attention \\n\\nAttention is the new currency \\n\\nMore time spent app gets hit\\n\\nWe cannot understand what we are not attending \\n\\nAm I controlling my attention or someone else ?\\n\\nAttention external or internal \\n\\nThink positive \\n\\nRepetition of positive then you will become positive person \\n\\nWhatever you want to learn do it at night.\\n\\nWe are emotional being as well \\n\\nLearning point of view\\n\\nAttention \\n\\nMultitasking\\n\\nWe are not multitasker \\n\\nBike example Sensory memory \\n\\n2 new things learning new language at the same time we cant use optimal use of our mind \\n\\nCar accident example \\n\\nScientifically it’s not possible \\n\\nForget things \\n\\nOptimal use = space practice \\n\\nForgetting curve occur start again learning \\n\\nStm>ltm> learning \\n\\nHeuristics \\n\\nWe are heavily relay on it \\n\\nPart3 \\n\\nHuman inspired AI\\n\\nAi learn from human\\n\\nNeural networks\\n\\nReinforcement learning – in psychology we call it operant conditioning \\n\\nAttention – transformers \\n\\nOccam’s razor- regularization \\n\\nConclusion\\n\\nInitially, AI researchers aimed to create human-like intelligences. Now, the field has become more specialized, focusing on specific domains like skin cancer detection\\n\\nAi general \\n\\nAgi through human intelligence'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/anjuai.pdf'}, page_content='The\\nceo\\nof\\nanju.ai\\nis\\nknooz\\nfatima.\\nArtificial\\nIntelligence\\nServices\\nanju.ai\\nbuilds\\nsolutions\\nonly\\nrelated\\nto\\ncomputer\\nvision.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.'),\n",
            "               Document(metadata={'page': 0.0, 'source': '/content/Untitled document.pdf'}, page_content='The\\nceo\\nof\\nBluescarf.ai\\nis\\nSarfaraz\\nAhmed\\nbehan.\\nArtificial\\nIntelligence\\nServices\\nBluescarf.ai\\nbuilds\\nsolutions\\nand\\nprovides\\nresearch\\nservices\\nin\\nGenerative\\nAI,\\nAdvanced\\nAudio\\nProcessing,\\nNatural\\nLanguage\\nProcessing,\\nDeep\\nLearning,\\nFoundational\\nModels\\nand\\nother\\nAI\\ntechnologies.')],\n",
            " 'question': 'Could you provide an in-depth 1000-word overview of artificial '\n",
            "             'intelligence, including its main branches and subfields?'}\n",
            "'\\n---\\n'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GraphRecursionError",
          "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-57f79f73f2a9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[0miteration_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iteration: {iteration_count}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Track iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0;31m# handle exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"out_of_steps\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                     raise GraphRecursionError(\n\u001b[0m\u001b[1;32m    967\u001b[0m                         \u001b[0;34mf\"Recursion limit of {config['recursion_limit']} reached \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                         \u001b[0;34m\"without hitting a stop condition. You can increase the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
          ]
        }
      ]
    }
  ]
}
